{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNT2dy8vaMQONphWpF2+p7P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DelCastillo777/holasaludo/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwAjREGr8zMe"
      },
      "outputs": [],
      "source": [
        "# --- CELDA 1: Importaciones y configuración de entorno ---\n",
        "# Importa todas las librerías necesarias y configura la carpeta de salida.\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"GPUs detectadas:\", tf.config.list_physical_devices(\"GPU\"))\n",
        "OUT = \"/content/mlp_iris_output\"\n",
        "os.makedirs(OUT, exist_ok=True)\n",
        "print(\"Salida:\", OUT)\n",
        "print(\"Fecha (UTC):\", datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELDA 2: Cargar, explorar y dividir el dataset IRIS ---\n",
        "# Carga el dataset Iris, muestra su forma y divide en train/test.\n",
        "iris = load_iris()\n",
        "X = iris.data          # 150 muestras, 4 características\n",
        "y = iris.target        # 3 clases balanceadas\n",
        "\n",
        "print(\"Características:\", iris.feature_names)\n",
        "print(\"Clases:\", iris.target_names)\n",
        "print(\"Forma de X:\", X.shape)\n",
        "print(\"Clases en y:\", np.unique(y, return_counts=True))\n",
        "\n",
        "# Visualización rápida: muestra dos primeras características\n",
        "plt.figure(figsize=(5,4))\n",
        "for i in range(3):\n",
        "    plt.scatter(X[y==i,0], X[y==i,1], label=iris.target_names[i], s=25)\n",
        "plt.xlabel(iris.feature_names[0])\n",
        "plt.ylabel(iris.feature_names[1])\n",
        "plt.title(\"Iris: Dos primeras características\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.savefig(os.path.join(OUT, \"iris_datos.png\"), dpi=120, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# División train/test (estratificada)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=123\n",
        ")"
      ],
      "metadata": {
        "id": "vlT1687T80U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELDA 3: Normalización y parámetros del modelo ---\n",
        "# Normaliza los datos (media y std del train) y define hiperparámetros.\n",
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "HIDDEN = 32        # neuronas en la capa oculta\n",
        "EPOCHS = 40\n",
        "BATCH = 16\n",
        "VALIDATION_SPLIT = 0.15"
      ],
      "metadata": {
        "id": "5Vep0AM3852Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELDA 4: Definición del modelo (MLP simple) ---\n",
        "# Modelo MLP: capa oculta + BatchNorm + Dropout + softmax (3 clases)\n",
        "inp = Input(shape=(4,), name=\"entrada_iris\")\n",
        "x = layers.Dense(HIDDEN, activation=\"relu\", name=\"densa_1\")(inp)\n",
        "x = layers.BatchNormalization(name=\"bn_1\")(x)\n",
        "x = layers.Dropout(0.2, name=\"dropout_1\")(x)\n",
        "out = layers.Dense(3, activation=\"softmax\", name=\"salida\")(x)\n",
        "\n",
        "model = Model(inputs=inp, outputs=out, name=\"mlp_iris\")\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zKXDTb9K9Icg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELDA 5: Entrenamiento y guardado del modelo ---\n",
        "cb = [tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)]\n",
        "hist = model.fit(\n",
        "    X_train_norm, y_train,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    callbacks=cb,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "model.save(os.path.join(OUT, \"modelo_iris.keras\"))\n",
        "\n",
        "# Graficas de accuracy y loss\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hist.history.get(\"accuracy\", []), label=\"train\")\n",
        "plt.plot(hist.history.get(\"val_accuracy\", []), label=\"val\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Accuracy\")\n",
        "plt.legend(); plt.grid(True); plt.title(\"Accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(hist.history.get(\"loss\", []), label=\"train\")\n",
        "plt.plot(hist.history.get(\"val_loss\", []), label=\"val\")\n",
        "plt.xlabel(\"Época\"); plt.ylabel(\"Loss\")\n",
        "plt.legend(); plt.grid(True); plt.title(\"Loss\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT, \"curvas.png\"), dpi=120, bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0y0XPOiL9OzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELDA 6: Evaluación y matriz de confusión ---\n",
        "loss, acc = model.evaluate(X_test_norm, y_test, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}  |  Test accuracy: {acc:.4f}\")\n",
        "\n",
        "# Predicciones y matriz de confusión\n",
        "y_pred = np.argmax(model.predict(X_test_norm, verbose=0), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Matriz de confusión (test)\")\n",
        "plt.savefig(os.path.join(OUT, \"matriz_confusion.png\"), dpi=120, bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gcqDahUU9Rgb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}